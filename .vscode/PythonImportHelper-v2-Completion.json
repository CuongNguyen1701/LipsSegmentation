[
    {
        "label": "streamlit",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "streamlit",
        "description": "streamlit",
        "detail": "streamlit",
        "documentation": {}
    },
    {
        "label": "Image",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "Image",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "hparams",
        "description": "hparams",
        "isExtraImport": true,
        "detail": "hparams",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "hparams",
        "description": "hparams",
        "isExtraImport": true,
        "detail": "hparams",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "hparams",
        "description": "hparams",
        "isExtraImport": true,
        "detail": "hparams",
        "documentation": {}
    },
    {
        "label": "get_model",
        "importPath": "model",
        "description": "model",
        "isExtraImport": true,
        "detail": "model",
        "documentation": {}
    },
    {
        "label": "get_model",
        "importPath": "model",
        "description": "model",
        "isExtraImport": true,
        "detail": "model",
        "documentation": {}
    },
    {
        "label": "cv2",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "cv2",
        "description": "cv2",
        "detail": "cv2",
        "documentation": {}
    },
    {
        "label": "time",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "time",
        "description": "time",
        "detail": "time",
        "documentation": {}
    },
    {
        "label": "numpy",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "numpy",
        "description": "numpy",
        "detail": "numpy",
        "documentation": {}
    },
    {
        "label": "tensorflow",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "tensorflow",
        "description": "tensorflow",
        "detail": "tensorflow",
        "documentation": {}
    },
    {
        "label": "keras",
        "importPath": "tensorflow",
        "description": "tensorflow",
        "isExtraImport": true,
        "detail": "tensorflow",
        "documentation": {}
    },
    {
        "label": "keras",
        "importPath": "tensorflow",
        "description": "tensorflow",
        "isExtraImport": true,
        "detail": "tensorflow",
        "documentation": {}
    },
    {
        "label": "create_colormap",
        "importPath": "cmap",
        "description": "cmap",
        "isExtraImport": true,
        "detail": "cmap",
        "documentation": {}
    },
    {
        "label": "keras.backend",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "keras.backend",
        "description": "keras.backend",
        "detail": "keras.backend",
        "documentation": {}
    },
    {
        "label": "ImageDataGenerator",
        "importPath": "keras.preprocessing.image",
        "description": "keras.preprocessing.image",
        "isExtraImport": true,
        "detail": "keras.preprocessing.image",
        "documentation": {}
    },
    {
        "label": "load_img",
        "importPath": "keras.preprocessing.image",
        "description": "keras.preprocessing.image",
        "isExtraImport": true,
        "detail": "keras.preprocessing.image",
        "documentation": {}
    },
    {
        "label": "Model",
        "importPath": "keras.models",
        "description": "keras.models",
        "isExtraImport": true,
        "detail": "keras.models",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "keras.layers",
        "description": "keras.layers",
        "isExtraImport": true,
        "detail": "keras.layers",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "keras.metrics",
        "description": "keras.metrics",
        "isExtraImport": true,
        "detail": "keras.metrics",
        "documentation": {}
    },
    {
        "label": "JaccardLoss",
        "importPath": "loss_functions",
        "description": "loss_functions",
        "isExtraImport": true,
        "detail": "loss_functions",
        "documentation": {}
    },
    {
        "label": "model",
        "kind": 5,
        "importPath": "app",
        "description": "app",
        "peekOfCode": "model = st.session_state[\"model\"]\nst.title(\"Webcam Live Feed\")\nrun = st.toggle(\"Run\", False)\ncolor = st.color_picker(\"Pick A Color\", \"#FF0000\")\nFRAME_WINDOW = st.image([])\ncap = cv2.VideoCapture(0)\ncolormap = create_colormap(\"#000000\", color)\n# Initialize variables for FPS calculation\nstart_time = time.time()\nframe_count = 0",
        "detail": "app",
        "documentation": {}
    },
    {
        "label": "run",
        "kind": 5,
        "importPath": "app",
        "description": "app",
        "peekOfCode": "run = st.toggle(\"Run\", False)\ncolor = st.color_picker(\"Pick A Color\", \"#FF0000\")\nFRAME_WINDOW = st.image([])\ncap = cv2.VideoCapture(0)\ncolormap = create_colormap(\"#000000\", color)\n# Initialize variables for FPS calculation\nstart_time = time.time()\nframe_count = 0\nfps_text = st.text(\"FPS: \")\nwhile run:",
        "detail": "app",
        "documentation": {}
    },
    {
        "label": "color",
        "kind": 5,
        "importPath": "app",
        "description": "app",
        "peekOfCode": "color = st.color_picker(\"Pick A Color\", \"#FF0000\")\nFRAME_WINDOW = st.image([])\ncap = cv2.VideoCapture(0)\ncolormap = create_colormap(\"#000000\", color)\n# Initialize variables for FPS calculation\nstart_time = time.time()\nframe_count = 0\nfps_text = st.text(\"FPS: \")\nwhile run:\n    ret, frame = cap.read()",
        "detail": "app",
        "documentation": {}
    },
    {
        "label": "FRAME_WINDOW",
        "kind": 5,
        "importPath": "app",
        "description": "app",
        "peekOfCode": "FRAME_WINDOW = st.image([])\ncap = cv2.VideoCapture(0)\ncolormap = create_colormap(\"#000000\", color)\n# Initialize variables for FPS calculation\nstart_time = time.time()\nframe_count = 0\nfps_text = st.text(\"FPS: \")\nwhile run:\n    ret, frame = cap.read()\n    frame = cv2.flip(frame, 1)",
        "detail": "app",
        "documentation": {}
    },
    {
        "label": "cap",
        "kind": 5,
        "importPath": "app",
        "description": "app",
        "peekOfCode": "cap = cv2.VideoCapture(0)\ncolormap = create_colormap(\"#000000\", color)\n# Initialize variables for FPS calculation\nstart_time = time.time()\nframe_count = 0\nfps_text = st.text(\"FPS: \")\nwhile run:\n    ret, frame = cap.read()\n    frame = cv2.flip(frame, 1)\n    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)",
        "detail": "app",
        "documentation": {}
    },
    {
        "label": "colormap",
        "kind": 5,
        "importPath": "app",
        "description": "app",
        "peekOfCode": "colormap = create_colormap(\"#000000\", color)\n# Initialize variables for FPS calculation\nstart_time = time.time()\nframe_count = 0\nfps_text = st.text(\"FPS: \")\nwhile run:\n    ret, frame = cap.read()\n    frame = cv2.flip(frame, 1)\n    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n    image = Image.fromarray(rgb_frame)",
        "detail": "app",
        "documentation": {}
    },
    {
        "label": "start_time",
        "kind": 5,
        "importPath": "app",
        "description": "app",
        "peekOfCode": "start_time = time.time()\nframe_count = 0\nfps_text = st.text(\"FPS: \")\nwhile run:\n    ret, frame = cap.read()\n    frame = cv2.flip(frame, 1)\n    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n    image = Image.fromarray(rgb_frame)\n    image = image.resize(IMAGE_SIZE)\n    image = np.array(image)",
        "detail": "app",
        "documentation": {}
    },
    {
        "label": "frame_count",
        "kind": 5,
        "importPath": "app",
        "description": "app",
        "peekOfCode": "frame_count = 0\nfps_text = st.text(\"FPS: \")\nwhile run:\n    ret, frame = cap.read()\n    frame = cv2.flip(frame, 1)\n    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n    image = Image.fromarray(rgb_frame)\n    image = image.resize(IMAGE_SIZE)\n    image = np.array(image)\n    image = tf.expand_dims(image, axis=0)",
        "detail": "app",
        "documentation": {}
    },
    {
        "label": "fps_text",
        "kind": 5,
        "importPath": "app",
        "description": "app",
        "peekOfCode": "fps_text = st.text(\"FPS: \")\nwhile run:\n    ret, frame = cap.read()\n    frame = cv2.flip(frame, 1)\n    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n    image = Image.fromarray(rgb_frame)\n    image = image.resize(IMAGE_SIZE)\n    image = np.array(image)\n    image = tf.expand_dims(image, axis=0)\n    predict_masks = model.predict(image)",
        "detail": "app",
        "documentation": {}
    },
    {
        "label": "hex_to_rgb",
        "kind": 2,
        "importPath": "cmap",
        "description": "cmap",
        "peekOfCode": "def hex_to_rgb(hex_color):\n    \"\"\"Convert hex color to RGB.\"\"\"\n    hex_color = hex_color.lstrip('#')\n    return tuple(int(hex_color[i:i+2], 16) for i in (4, 2, 0))\ndef create_colormap(color1, color2):\n    \"\"\"Create a colormap for cv2.applyColorMap from two hex RGB values(BGR value).\"\"\"\n    # Convert hex to RGB\n    rgb1 = hex_to_rgb(color1)\n    rgb2 = hex_to_rgb(color2)\n    # Generate gradient",
        "detail": "cmap",
        "documentation": {}
    },
    {
        "label": "create_colormap",
        "kind": 2,
        "importPath": "cmap",
        "description": "cmap",
        "peekOfCode": "def create_colormap(color1, color2):\n    \"\"\"Create a colormap for cv2.applyColorMap from two hex RGB values(BGR value).\"\"\"\n    # Convert hex to RGB\n    rgb1 = hex_to_rgb(color1)\n    rgb2 = hex_to_rgb(color2)\n    # Generate gradient\n    gradient = np.linspace(rgb1, rgb2, 256)\n    # Convert to uint8\n    colormap = gradient.astype(np.uint8)\n    # Reshape to 256x1x3",
        "detail": "cmap",
        "documentation": {}
    },
    {
        "label": "outputs_folder",
        "kind": 5,
        "importPath": "hparams",
        "description": "hparams",
        "peekOfCode": "outputs_folder = \"./\"\n# Define the batch size and image dimensions\nBATCH_SIZE = 64\nIMAGE_HEIGHT = 256\nIMAGE_WIDTH = 256\nIMAGE_SIZE = (IMAGE_HEIGHT, IMAGE_WIDTH)\nSEED=5005",
        "detail": "hparams",
        "documentation": {}
    },
    {
        "label": "BATCH_SIZE",
        "kind": 5,
        "importPath": "hparams",
        "description": "hparams",
        "peekOfCode": "BATCH_SIZE = 64\nIMAGE_HEIGHT = 256\nIMAGE_WIDTH = 256\nIMAGE_SIZE = (IMAGE_HEIGHT, IMAGE_WIDTH)\nSEED=5005",
        "detail": "hparams",
        "documentation": {}
    },
    {
        "label": "IMAGE_HEIGHT",
        "kind": 5,
        "importPath": "hparams",
        "description": "hparams",
        "peekOfCode": "IMAGE_HEIGHT = 256\nIMAGE_WIDTH = 256\nIMAGE_SIZE = (IMAGE_HEIGHT, IMAGE_WIDTH)\nSEED=5005",
        "detail": "hparams",
        "documentation": {}
    },
    {
        "label": "IMAGE_WIDTH",
        "kind": 5,
        "importPath": "hparams",
        "description": "hparams",
        "peekOfCode": "IMAGE_WIDTH = 256\nIMAGE_SIZE = (IMAGE_HEIGHT, IMAGE_WIDTH)\nSEED=5005",
        "detail": "hparams",
        "documentation": {}
    },
    {
        "label": "IMAGE_SIZE",
        "kind": 5,
        "importPath": "hparams",
        "description": "hparams",
        "peekOfCode": "IMAGE_SIZE = (IMAGE_HEIGHT, IMAGE_WIDTH)\nSEED=5005",
        "detail": "hparams",
        "documentation": {}
    },
    {
        "label": "model",
        "kind": 5,
        "importPath": "inference",
        "description": "inference",
        "peekOfCode": "model = get_model(\"lips_model_unet.h5\")\n# Open the camera\ncap = cv2.VideoCapture(0)\n# Check if the webcam is opened correctly\nif not cap.isOpened():\n    raise IOError(\"Cannot open webcam\")\n# used to record the time when we processed last frame \nprev_frame_time = 0\n# used to record the time at which we processed current frame \nnew_frame_time = 0",
        "detail": "inference",
        "documentation": {}
    },
    {
        "label": "cap",
        "kind": 5,
        "importPath": "inference",
        "description": "inference",
        "peekOfCode": "cap = cv2.VideoCapture(0)\n# Check if the webcam is opened correctly\nif not cap.isOpened():\n    raise IOError(\"Cannot open webcam\")\n# used to record the time when we processed last frame \nprev_frame_time = 0\n# used to record the time at which we processed current frame \nnew_frame_time = 0\nwhile (True): \n    ret, frame = cap.read()",
        "detail": "inference",
        "documentation": {}
    },
    {
        "label": "prev_frame_time",
        "kind": 5,
        "importPath": "inference",
        "description": "inference",
        "peekOfCode": "prev_frame_time = 0\n# used to record the time at which we processed current frame \nnew_frame_time = 0\nwhile (True): \n    ret, frame = cap.read()\n    # Convert the image to PIL format\n    image = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n    image = image.resize(IMAGE_SIZE)\n    image = np.array(image)\n    image = tf.expand_dims(image, axis=0)",
        "detail": "inference",
        "documentation": {}
    },
    {
        "label": "new_frame_time",
        "kind": 5,
        "importPath": "inference",
        "description": "inference",
        "peekOfCode": "new_frame_time = 0\nwhile (True): \n    ret, frame = cap.read()\n    # Convert the image to PIL format\n    image = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n    image = image.resize(IMAGE_SIZE)\n    image = np.array(image)\n    image = tf.expand_dims(image, axis=0)\n    predict_masks = model.predict(image)\n    # Apply the mask to the original frame",
        "detail": "inference",
        "documentation": {}
    },
    {
        "label": "JaccardLoss",
        "kind": 2,
        "importPath": "loss_functions",
        "description": "loss_functions",
        "peekOfCode": "def JaccardLoss(targets, inputs, smooth=1e-6):\n    # Convert targets to float32 data type\n    targets = keras_be.cast(targets, dtype='float32')\n    # Flatten label and prediction tensors\n    inputs = keras_be.flatten(inputs)\n    targets = keras_be.flatten(targets)\n    # Reshape flattened tensors to rank-2 matrices\n    inputs = keras_be.reshape(inputs, (-1, 1))\n    targets = keras_be.reshape(targets, (-1, 1))\n    # Calculate intersection and union using dot product",
        "detail": "loss_functions",
        "documentation": {}
    },
    {
        "label": "PreprocessingBlock",
        "kind": 6,
        "importPath": "model",
        "description": "model",
        "peekOfCode": "class PreprocessingBlock(Layer):\n    def __init__(self, image_size=IMAGE_SIZE, scale=1./255):\n        super().__init__()\n        self.resize = Resizing(IMAGE_SIZE[0], IMAGE_SIZE[1])\n        self.rescale = Rescaling(scale=1./255)\n    def call(self, x):\n        x = self.resize(x)\n        x = self.rescale(x)\n        return x\nclass ConvBlock(Layer):",
        "detail": "model",
        "documentation": {}
    },
    {
        "label": "ConvBlock",
        "kind": 6,
        "importPath": "model",
        "description": "model",
        "peekOfCode": "class ConvBlock(Layer):\n        def __init__(self, filters, kernel_size, strides=1, padding='same', drop_out_rate=0.1, pool=False):\n            super().__init__()\n            self.conv = Conv2D(filters=filters, kernel_size=kernel_size, strides=strides, padding=padding, kernel_initializer='he_normal')\n            self.dropout = Dropout(drop_out_rate)\n            self.norm = BatchNormalization()\n            self.relu = LeakyReLU(0.1)\n        def call(self, x):\n            x = self.conv(x)\n            x = self.norm(x)",
        "detail": "model",
        "documentation": {}
    },
    {
        "label": "UpConvBlock",
        "kind": 6,
        "importPath": "model",
        "description": "model",
        "peekOfCode": "class UpConvBlock(Layer):\n    def __init__(self, filters, kernel_size, strides=2, padding='same', drop_out_rate=0.1, use_attention=False):\n            super().__init__()\n            self.tconv = Conv2DTranspose(filters=filters, kernel_size=kernel_size, strides=strides, padding=padding, kernel_initializer='he_normal')\n            self.dropout = Dropout(drop_out_rate)\n            self.norm = BatchNormalization()\n            self.relu = ReLU()\n            self.concat = Concatenate(axis=3)\n            self.use_attention = use_attention\n            self.attention = AdditiveAttention()",
        "detail": "model",
        "documentation": {}
    },
    {
        "label": "get_model",
        "kind": 2,
        "importPath": "model",
        "description": "model",
        "peekOfCode": "def get_model(pretrain_path=None):\n    inputs = Input((None, None, 3))\n    preprocessed = PreprocessingBlock()(inputs)\n    conv1 = ConvBlock(16, 3)(preprocessed)\n    conv1 = ConvBlock(16, 3)(conv1) \n    pool1 = MaxPooling2D((2,2))(conv1)\n    conv2 = ConvBlock(32, 3)(pool1)\n    conv2 = ConvBlock(32, 3)(conv2)\n    pool2 = MaxPooling2D((2,2))(conv2)\n    conv3 = ConvBlock(64, 3)(pool2)",
        "detail": "model",
        "documentation": {}
    }
]